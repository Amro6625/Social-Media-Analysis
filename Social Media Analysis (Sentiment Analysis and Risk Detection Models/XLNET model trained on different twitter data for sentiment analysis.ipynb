{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8058fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d619edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers requests beautifulsoup4 pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eaeb0c1-ca7d-4622-8638-f702c4764f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf406a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import plotly.express as px\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "import re \n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "lb = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac50aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94cb498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c71658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74681 entries, 0 to 74680\n",
      "Data columns (total 4 columns):\n",
      " #   Column                                                 Non-Null Count  Dtype \n",
      "---  ------                                                 --------------  ----- \n",
      " 0   2401                                                   74681 non-null  int64 \n",
      " 1   Borderlands                                            74681 non-null  object\n",
      " 2   Positive                                               74681 non-null  object\n",
      " 3   im getting on borderlands and i will murder you all ,  73995 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33118e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Positive'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b04f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['im getting on borderlands and i will murder you all ,'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f861efa9-2072-4e27-a2c0-c5dd56a95b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80916300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.rename(columns={\"Borderlands\":\"Feature2\",\"im getting on borderlands and i will murder you all ,\":\"Feature1\",\"Positive\": \"labels\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf97e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweets\"]= df[\"Feature1\"].astype(str) +\" \"+ df[\"Feature2\"].astype(str)\n",
    "df= df.drop([\"Feature1\",\"Feature2\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3cb7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_len'] = [len(text.split()) for text in df.tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f35aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df['tweet_len'] < 5) & ~(df['tweet_len'] > 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9802d184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Irrelevant': 0, 'Negative': 1, 'Neutral': 2, 'Positive': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = {key : value for value , key in enumerate(np.unique(df['labels']))}\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "423e8363-39a0-4660-8076-a9fd66778c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'labels' is the column name in your DataFrame\n",
    "df = df[df['labels'] != 'Irrelevant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "413385b5-2e33-40a8-bcb7-8dc5fbe0fd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "Negative    9805\n",
       "Positive    8738\n",
       "Neutral     8080\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d7a7039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2401</th>\n",
       "      <th>labels</th>\n",
       "      <th>tweets</th>\n",
       "      <th>tweet_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38713</th>\n",
       "      <td>5442</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Thanks to @ Kain0025 for the raid. Thanks to @...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>4692</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>How not to get bored about every damn thing in...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45892</th>\n",
       "      <td>11877</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>This comes as Facebook faces major criticism f...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68307</th>\n",
       "      <td>3697</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I'and d rather a delayed game than a broken di...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19912</th>\n",
       "      <td>12608</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>yeah its alright for fighting some raid here i...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57886</th>\n",
       "      <td>11526</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>You guys are missing both not seeing my squad ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14818</th>\n",
       "      <td>2938</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I've been at a lot of unranked in DotA 2. (SEA...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>2688</td>\n",
       "      <td>Positive</td>\n",
       "      <td>All 3 of these are me! I wore Tannis and Hands...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38544</th>\n",
       "      <td>5411</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Ouch, the Pain Zone powered by The Nuclear Arc...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24951</th>\n",
       "      <td>4684</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>For @narendramodi i will am unable to exclusiv...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26623 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        2401    labels                                             tweets  \\\n",
       "38713   5442  Positive  Thanks to @ Kain0025 for the raid. Thanks to @...   \n",
       "24996   4692   Neutral  How not to get bored about every damn thing in...   \n",
       "45892  11877   Neutral  This comes as Facebook faces major criticism f...   \n",
       "68307   3697   Neutral  I'and d rather a delayed game than a broken di...   \n",
       "19912  12608   Neutral  yeah its alright for fighting some raid here i...   \n",
       "...      ...       ...                                                ...   \n",
       "57886  11526   Neutral  You guys are missing both not seeing my squad ...   \n",
       "14818   2938  Positive  I've been at a lot of unranked in DotA 2. (SEA...   \n",
       "1640    2688  Positive  All 3 of these are me! I wore Tannis and Hands...   \n",
       "38544   5411   Neutral  Ouch, the Pain Zone powered by The Nuclear Arc...   \n",
       "24951   4684   Neutral  For @narendramodi i will am unable to exclusiv...   \n",
       "\n",
       "       tweet_len  \n",
       "38713         44  \n",
       "24996         12  \n",
       "45892         19  \n",
       "68307         12  \n",
       "19912         32  \n",
       "...          ...  \n",
       "57886         15  \n",
       "14818         35  \n",
       "1640          14  \n",
       "38544         22  \n",
       "24951         18  \n",
       "\n",
       "[26623 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ed78032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the tweets\n",
    "def preprocess_tweet(tweet):\n",
    "\n",
    "    # Removing the mentions\n",
    "    tweet = re.sub(r'@[\\w]+', '', tweet)\n",
    "\n",
    "    # Removing hashtags\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    \n",
    "    # Removing URLs\n",
    "    tweet = re.sub(r'https?://\\S+', '', tweet)\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
    "    \n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stopwords]\n",
    "\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Cleaned_Tweet'] = df['tweets'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f28b0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# Fit and transform labels\n",
    "df['labels'] = lb.fit_transform(df['labels'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f03be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da646f47-c1b2-4e47-8240-88c98f1ee138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])  # Ensure labels are already converted to numerical format\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f85ae4e9-1f4e-458d-b005-a010a9264d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 0.8\n",
    "torch.cuda.set_per_process_memory_fraction(fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bca2aeca-8caa-48cf-a4fa-cdd5dd635423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and model\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e0cd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into train and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['Cleaned_Tweet'].values,\n",
    "    df['labels'].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f80561d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and DataLoader for training\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CustomDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b571a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1476d3ad-eeb4-484a-acd9-71ca7413914b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [24:03<00:00,  4.15it/s]\n",
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:58<00:00,  4.17it/s]\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:55<00:00,  4.17it/s]\n",
      "Epoch 7: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 8: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 10: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 11: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 12: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 13: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 14: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 15: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 16: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 17: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 18: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n",
      "Epoch 19: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 20: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 21: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 22: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 23: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:57<00:00,  4.17it/s]\n",
      "Epoch 24: 100%|████████████████████████████████████████████████████████████████████| 5990/5990 [23:56<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Move the model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "epochs = 25\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d928cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████| 666/666 [00:53<00:00, 12.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       987\n",
      "           1       0.90      0.89      0.90       820\n",
      "           2       0.88      0.91      0.89       856\n",
      "\n",
      "    accuracy                           0.90      2663\n",
      "   macro avg       0.90      0.90      0.90      2663\n",
      "weighted avg       0.90      0.90      0.90      2663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "model.eval()\n",
    "val_preds = []\n",
    "val_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(val_true, val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "728eea93-1fc5-41dd-89b4-c1809a9ac81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('XLNET_sentiment_tokenizer\\\\tokenizer_config.json',\n",
       " 'XLNET_sentiment_tokenizer\\\\special_tokens_map.json',\n",
       " 'XLNET_sentiment_tokenizer\\\\spiece.model',\n",
       " 'XLNET_sentiment_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('XLNET_sentiment_model')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('XLNET_sentiment_tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1728301-1640-4d54-81fa-65830a52f16a",
   "metadata": {},
   "source": [
    "# XlNET Model for Risk Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b14bd9-e303-4557-9afe-7fb097548bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Excel file\n",
    "df_new = pd.read_excel('negative_sentiments.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f64776-d886-423f-a1c3-d10986a69090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating labeled and unlabeled data\n",
    "predict_df_new = df_new[df_new['Label'].isna()]\n",
    "train_df_new = df_new.dropna(subset=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee2d3697-6d04-4798-a665-18daa427408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and model loading\n",
    "tokenizer_new = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "model_new = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e021e39-02ef-4e52-81bc-72813ecd5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and preparing DataLoader for training\n",
    "class CustomDatasetNew(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77754c88-cf28-42ad-9a46-0aec2e810cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into train and validation sets\n",
    "train_texts_new, val_texts_new, train_labels_new, val_labels_new = train_test_split(\n",
    "    train_df_new['Cleaned_Tweet'].values,\n",
    "    train_df_new['Label'].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0261a82a-d0bf-4301-922b-a5abedaad7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datasets and DataLoader for training\n",
    "train_dataset_new = CustomDatasetNew(train_texts_new, train_labels_new, tokenizer_new)\n",
    "val_dataset_new = CustomDatasetNew(val_texts_new, val_labels_new, tokenizer_new)\n",
    "\n",
    "train_loader_new = DataLoader(train_dataset_new, batch_size=8, shuffle=True)\n",
    "val_loader_new = DataLoader(val_dataset_new, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da89fd8b-ae1a-44f3-ae88-6f96c30aaf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cde735c91224f34bcf4354e369fa7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6a92f457b345579c3dac7ed3ae47fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c30d6654b1450fac05a508fc57fef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500d09f266d146c5b91dd627026d794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29928437672a41818e4b0c323fbbb404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a00ff9603f430eaa030151c3998a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0db499f5304262a56a8ff08c4ff434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6daf53fb2008423ca517b4c3a2229730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cd45c9a31840418281118575dbed43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02a2f474cb849b8b8c9a4e9c1e859a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0699ce95b3ce47749f51ff3946b790ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b817ba0a6c524f1c857a23170bacc968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44ae2cdbd6f4d078d53d85a71e6b7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74748bc8cb8e4e0ba0241f77e0886f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb2d52a00c643259838377b39825b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355a1a815d03430bba85bf3f86bc6ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping after 8 epochs without improvement.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "device_new = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_new.to(device_new)\n",
    "\n",
    "optimizer_new = torch.optim.AdamW(model_new.parameters(), lr=2e-5)\n",
    "epochs_new = 100\n",
    "\n",
    "best_val_loss_new = float('inf')\n",
    "patience_new = 5  \n",
    "counter_new = 0\n",
    "\n",
    "for epoch_new in range(epochs_new):\n",
    "    # Training loop\n",
    "    model_new.train()\n",
    "    for batch_new in tqdm(train_loader_new, desc=f\"Epoch {epoch_new}\"):\n",
    "        input_ids_new = batch_new['input_ids'].to(device_new)\n",
    "        attention_mask_new = batch_new['attention_mask'].to(device_new)\n",
    "        labels_new = batch_new['label'].to(device_new)\n",
    "\n",
    "        optimizer_new.zero_grad()\n",
    "\n",
    "        outputs_new = model_new(input_ids_new, attention_mask=attention_mask_new, labels=labels_new)\n",
    "        loss_new = outputs_new.loss\n",
    "        loss_new.backward()\n",
    "\n",
    "        optimizer_new.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model_new.eval()\n",
    "    val_loss_new = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_new in tqdm(val_loader_new, desc=\"Validation\"):\n",
    "            input_ids_new = batch_new['input_ids'].to(device_new)\n",
    "            attention_mask_new = batch_new['attention_mask'].to(device_new)\n",
    "            labels_new = batch_new['label'].to(device_new)\n",
    "\n",
    "            outputs_new = model_new(input_ids_new, attention_mask=attention_mask_new)\n",
    "            logits_new = outputs_new.logits\n",
    "            preds_new = torch.argmax(logits_new, dim=1)\n",
    "            loss_new = torch.nn.functional.cross_entropy(logits_new, labels_new)\n",
    "\n",
    "            val_loss_new += loss_new.item()\n",
    "\n",
    "    # Calculating average validation loss\n",
    "    avg_val_loss_new = val_loss_new / len(val_loader_new)\n",
    "\n",
    "    # Checking for early stopping\n",
    "    if avg_val_loss_new < best_val_loss_new:\n",
    "        best_val_loss_new = avg_val_loss_new\n",
    "        counter_new = 0\n",
    "    else:\n",
    "        counter_new += 1\n",
    "\n",
    "    if counter_new >= patience_new:\n",
    "        print(f'Early stopping after {epoch_new + 1} epochs without improvement.')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df4651d-bbb1-4878-8b76-ddf9942ac895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24071421d582490e840c484a717ed418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        15\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.94        16\n",
      "   macro avg       0.47      0.50      0.48        16\n",
      "weighted avg       0.88      0.94      0.91        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation of the model\n",
    "model_new.eval()\n",
    "val_preds_new = []\n",
    "val_true_new = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_new in tqdm(val_loader_new, desc=\"Validation\"):\n",
    "        input_ids_new = batch_new['input_ids'].to(device_new)\n",
    "        attention_mask_new = batch_new['attention_mask'].to(device_new)\n",
    "        labels_new = batch_new['label'].to(device_new)\n",
    "\n",
    "        outputs_new = model_new(input_ids_new, attention_mask=attention_mask_new)\n",
    "        logits_new = outputs_new.logits\n",
    "        preds_new = torch.argmax(logits_new, dim=1)\n",
    "\n",
    "        val_preds_new.extend(preds_new.cpu().numpy())\n",
    "        val_true_new.extend(labels_new.cpu().numpy())\n",
    "\n",
    "print(classification_report(val_true_new, val_preds_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ee297e-069f-4ac8-9c4f-24582f4957c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0625\n",
      "Mean Absolute Error (MAE): 0.0625\n",
      "R-squared (R2) Score: -0.0667\n"
     ]
    }
   ],
   "source": [
    "# Calculating Mean Squared Error (MSE)\n",
    "mse_new = mean_squared_error(val_true_new, val_preds_new)\n",
    "print(f\"Mean Squared Error (MSE): {mse_new:.4f}\")\n",
    "\n",
    "# Calculating Mean Absolute Error (MAE)\n",
    "mae_new = mean_absolute_error(val_true_new, val_preds_new)\n",
    "print(f\"Mean Absolute Error (MAE): {mae_new:.4f}\")\n",
    "\n",
    "# Calculating R-squared (R2) score\n",
    "r2_new = r2_score(val_true_new, val_preds_new)\n",
    "print(f\"R-squared (R2) Score: {r2_new:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8ad43f-3317-4649-badb-7b24b5da5a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Had a wonderful time in hull today\n",
      "Predicted Label: 0\n",
      "Probability: 0.9510\n",
      "\n",
      "Sentence: there is a fire in the south street we need the your assistance @HumbersideFire\n",
      "Predicted Label: 0\n",
      "Probability: 0.9837\n",
      "\n",
      "Sentence: The kids are lighting fireworks in pearson park it is really dangerous\n",
      "Predicted Label: 0\n",
      "Probability: 0.8169\n",
      "\n",
      "Sentence: I see smoke coming from the paragon station\n",
      "Predicted Label: 0\n",
      "Probability: 0.9306\n",
      "\n",
      "Sentence: Some teenager are jumping of the bridge into the water\n",
      "Predicted Label: 0\n",
      "Probability: 0.9757\n",
      "\n",
      "Sentence: There is no incident in the beverly road\n",
      "Predicted Label: 0\n",
      "Probability: 0.8482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample list of sentences\n",
    "sentences_new = [\"Had a wonderful time in hull today\",\"there is a fire in the south street we need the your assistance @HumbersideFire\", \"The kids are lighting fireworks in pearson park it is really dangerous\", \"I see smoke coming from the paragon station\", \"Some teenager are jumping of the bridge into the water\",\"There is no incident in the beverly road\"]\n",
    "\n",
    "# Tokenize the list of sentences\n",
    "inputs_new = tokenizer_new(sentences_new, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "# Forward pass through the model\n",
    "outputs_new = model_new(**inputs_new)\n",
    "\n",
    "# Apply softmax to get predictions\n",
    "predictions_new = torch.nn.functional.softmax(outputs_new.logits, dim=-1)\n",
    "\n",
    "# Convert predictions to numpy array\n",
    "predictions_new = predictions_new.cpu().detach().numpy()\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels_new = [np.argmax(pred) for pred in predictions_new]\n",
    "\n",
    "# Get the corresponding probabilities\n",
    "probs_new = [pred[label] for pred, label in zip(predictions_new, predicted_labels_new)]\n",
    "\n",
    "# Print results\n",
    "for sentence_new, label_new, prob_new in zip(sentences_new, predicted_labels_new, probs_new):\n",
    "    print(f\"Sentence: {sentence_new}\")\n",
    "    print(f\"Predicted Label: {label_new}\")\n",
    "    print(f\"Probability: {prob_new:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc849a4d-0c26-49f2-962b-e2ff1cebbb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = int(self.labels[idx])\n",
    "        else:\n",
    "            label = None\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long) if label is not None else None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8148234-f2be-4829-845f-082d41899309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading file with data for prediction\n",
    "new_df = pd.read_excel('Labeled_Tweets.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23ffeb2d-f6b6-4d40-b225-866ba4606d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5436a61e8f084d3fa39b1a55888c48e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming 'Cleaned_Tweet' is the column containing the text data for prediction\n",
    "new_texts = new_df['Cleaned_Tweet'].values\n",
    "\n",
    "# Tokenize and prepare DataLoader for prediction\n",
    "new_dataset = CustomDataset(new_texts, labels=None, tokenizer=tokenizer_new, max_len=128)\n",
    "new_loader = DataLoader(new_dataset, batch_size=8, shuffle=False, collate_fn=lambda x: x)\n",
    "\n",
    "# Make predictions\n",
    "model_new.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(new_loader, desc=\"Predicting\"):\n",
    "        input_ids = torch.stack([item['input_ids'] for item in batch]).to(device_new)\n",
    "        attention_mask = torch.stack([item['attention_mask'] for item in batch]).to(device_new)\n",
    "\n",
    "        outputs = model_new(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efa82243-a6ac-4f62-8759-05396a5fc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the DataFrame\n",
    "new_df['XLNET_Prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "144023e5-714f-4f40-9c7a-6d8e3fd2340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Label</th>\n",
       "      <th>XLNET_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bev</td>\n",
       "      <td>@GyAncient @nige_gallop @CCLeeFreeman @Cleeccs...</td>\n",
       "      <td>bagger amazed knew walking football result yes...</td>\n",
       "      <td>0.519025</td>\n",
       "      <td>0.442044</td>\n",
       "      <td>0.038931</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nigel 💙</td>\n",
       "      <td>@GyAncient @BevskiMids @CCLeeFreeman @Cleeccsc...</td>\n",
       "      <td>blimey mick old dog</td>\n",
       "      <td>0.677478</td>\n",
       "      <td>0.285934</td>\n",
       "      <td>0.036588</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nigel 💙</td>\n",
       "      <td>@BevskiMids @CCLeeFreeman @Cleeccsc @Humberbea...</td>\n",
       "      <td>wondered rd right obvs due play rare midweek g...</td>\n",
       "      <td>0.763980</td>\n",
       "      <td>0.222234</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iain Joseph Gorry*</td>\n",
       "      <td>@Cleeccsc @JoRobbo68 @Humberbeat @HumbersideFi...</td>\n",
       "      <td>guy tweet date wrong think</td>\n",
       "      <td>0.664363</td>\n",
       "      <td>0.322601</td>\n",
       "      <td>0.013036</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North East Lincolnshire Council</td>\n",
       "      <td>What are the biggest crime issues in North Eas...</td>\n",
       "      <td>biggest crime issue north east lincolnshire te...</td>\n",
       "      <td>0.662119</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.017346</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Yorkshire Fire</td>\n",
       "      <td>We spent weeks tackling a fire on Hatfield Moo...</td>\n",
       "      <td>spent week tackling fire hatfield moor despera...</td>\n",
       "      <td>0.560314</td>\n",
       "      <td>0.336407</td>\n",
       "      <td>0.103279</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Humberside Police - North East Lincolnshire</td>\n",
       "      <td>#Grimsby #Willows Attended an incident tonight...</td>\n",
       "      <td>attended incident tonight binbrook way group y...</td>\n",
       "      <td>0.889538</td>\n",
       "      <td>0.104743</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Safer Roads Humber</td>\n",
       "      <td>A fire safety message today. With more people ...</td>\n",
       "      <td>fire safety message today people easy overload...</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.462393</td>\n",
       "      <td>0.023321</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>North Lincs Council</td>\n",
       "      <td>Just because it's warm outside, it doesn't mea...</td>\n",
       "      <td>warm outside doesnt mean warm underwater cold ...</td>\n",
       "      <td>0.698401</td>\n",
       "      <td>0.289254</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DC_LK1989</td>\n",
       "      <td>Unfortunately I’m going to say no...our street...</td>\n",
       "      <td>unfortunately im going say noour street would ...</td>\n",
       "      <td>0.875694</td>\n",
       "      <td>0.117654</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alan Clark 💙 🇺🇦 🇪🇺 🇬🇧</td>\n",
       "      <td>@Fionamills1 @Humber_01 @HareWolfy @LouiseWrit...</td>\n",
       "      <td>didnt think would put outfit last incident</td>\n",
       "      <td>0.504043</td>\n",
       "      <td>0.470565</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Park Street Performing Arts</td>\n",
       "      <td>@HareWolfy @Humber_01 @Fionamills1 @LouiseWrit...</td>\n",
       "      <td>sliding batpole must fraught pain danger wolfy</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>0.341539</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lincolnshire Fire and Rescue</td>\n",
       "      <td>13:26 1/2 Wholetime and On-Call Crew from @Gai...</td>\n",
       "      <td>wholetime oncall crew appliance misterton amp ...</td>\n",
       "      <td>0.538386</td>\n",
       "      <td>0.443323</td>\n",
       "      <td>0.018291</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>russell</td>\n",
       "      <td>@HumbersideFire Glad no one injured 👍 i have b...</td>\n",
       "      <td>glad one injured back work week realise mad li...</td>\n",
       "      <td>0.590768</td>\n",
       "      <td>0.373226</td>\n",
       "      <td>0.036006</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mark Webb</td>\n",
       "      <td>@CFOBlacksell @HumbersideFire @Humberbeat This...</td>\n",
       "      <td>lazy gutterpress journalism embarrassment wors...</td>\n",
       "      <td>0.962897</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>James Mitchinson</td>\n",
       "      <td>@CFOBlacksell @HumbersideFire @Humberbeat Well...</td>\n",
       "      <td>well said chris sorry medium making job difficult</td>\n",
       "      <td>0.747294</td>\n",
       "      <td>0.234820</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bog-trotter</td>\n",
       "      <td>@Marktur03393381 @SYFR @WYFRS @LancashireFRS @...</td>\n",
       "      <td>day sequestration capacity lost c acre sssi na...</td>\n",
       "      <td>0.723867</td>\n",
       "      <td>0.256126</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CSB</td>\n",
       "      <td>@PCSODarrenB @HumbersideFire Over the limit? N...</td>\n",
       "      <td>limit sympathy im afraid</td>\n",
       "      <td>0.808927</td>\n",
       "      <td>0.180259</td>\n",
       "      <td>0.010814</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rob Buckle</td>\n",
       "      <td>@sunkfarmer @PCSODarrenB @HumbersideFire Misse...</td>\n",
       "      <td>missed wall end inch look</td>\n",
       "      <td>0.510658</td>\n",
       "      <td>0.459784</td>\n",
       "      <td>0.029558</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sheffield Environmental</td>\n",
       "      <td>@BryonyHolroyd @AndyMbirder @4peatssake2 @Wint...</td>\n",
       "      <td>grazers would eaten low braches still place li...</td>\n",
       "      <td>0.612657</td>\n",
       "      <td>0.372969</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bog-trotter</td>\n",
       "      <td>@paulbrear @HumbersideFire @SYFR Today (30 May...</td>\n",
       "      <td>today may day amp day use helicopter show seri...</td>\n",
       "      <td>0.852878</td>\n",
       "      <td>0.140245</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chris spavin</td>\n",
       "      <td>@HumbersideFire Hi sorry to both you. Just won...</td>\n",
       "      <td>hi sorry wondered letter posted mum letter box...</td>\n",
       "      <td>0.871667</td>\n",
       "      <td>0.120409</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Guy Hitchins</td>\n",
       "      <td>@HumbersideFire @SYFR Sooo much of this going ...</td>\n",
       "      <td>sooo much going present avoidable sadly helico...</td>\n",
       "      <td>0.521803</td>\n",
       "      <td>0.400316</td>\n",
       "      <td>0.077880</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hull 4 Heroes</td>\n",
       "      <td>Five families had their lives turned upside do...</td>\n",
       "      <td>five family life turned upside arsonist hull i...</td>\n",
       "      <td>0.766391</td>\n",
       "      <td>0.223161</td>\n",
       "      <td>0.010447</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Farmers Weekly</td>\n",
       "      <td>Top marks @HumbersideFire 👍 Sky lanterns start...</td>\n",
       "      <td>top mark sky lantern start fire deadly farm an...</td>\n",
       "      <td>0.744505</td>\n",
       "      <td>0.243972</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PCSO Darren Bainton</td>\n",
       "      <td>Please avoid using #SkyLanterns when showing y...</td>\n",
       "      <td>please avoid using showing appreciation nh amp...</td>\n",
       "      <td>0.772356</td>\n",
       "      <td>0.217180</td>\n",
       "      <td>0.010464</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dave Nassau</td>\n",
       "      <td>@Dr_Dan_1 @HumbersideFire @ChrisGPackham @Bell...</td>\n",
       "      <td>please please please please dont set sky lante...</td>\n",
       "      <td>0.963210</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Debs B 🌱</td>\n",
       "      <td>@BBCLookNorth @HumbersideFire Emergency servic...</td>\n",
       "      <td>emergency service enough dealing earth lantern...</td>\n",
       "      <td>0.686192</td>\n",
       "      <td>0.303560</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Elephant in The Room Disability Services</td>\n",
       "      <td>@CEXHCC @21_hardy @Hullccnews @NHSHullCCG @NHS...</td>\n",
       "      <td>also dedicated email cant use phone deaf non v...</td>\n",
       "      <td>0.709626</td>\n",
       "      <td>0.275995</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RSPCA Frontline</td>\n",
       "      <td>Thank you to @HumbersideFire for assisting Ins...</td>\n",
       "      <td>thank assisting insp hutton evening bridlingto...</td>\n",
       "      <td>0.771515</td>\n",
       "      <td>0.213819</td>\n",
       "      <td>0.014666</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Howard Davies</td>\n",
       "      <td>@shooter724 @Humberbeat @HumbersideFire The no...</td>\n",
       "      <td>nose know fooling etta</td>\n",
       "      <td>0.486248</td>\n",
       "      <td>0.454826</td>\n",
       "      <td>0.058925</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jon T</td>\n",
       "      <td>The CPAD at #Patrington fire station is now ba...</td>\n",
       "      <td>cpad fire station back running ive replaced un...</td>\n",
       "      <td>0.531859</td>\n",
       "      <td>0.422922</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jazzmariner ⚫️⚪️😁👏</td>\n",
       "      <td>@JKH62 @EnvAgencyYNE @johncurtinEA @EnvAgency ...</td>\n",
       "      <td>presumably dont agree science dredging would m...</td>\n",
       "      <td>0.492322</td>\n",
       "      <td>0.480894</td>\n",
       "      <td>0.026784</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Lankyshirelad</td>\n",
       "      <td>@EnvAgencyYNE @johncurtinEA @EnvAgency @TobyWi...</td>\n",
       "      <td>dredging sediment crap river start</td>\n",
       "      <td>0.892963</td>\n",
       "      <td>0.099527</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Phillip Norton</td>\n",
       "      <td>A public meeting is taking place at Snaith Pri...</td>\n",
       "      <td>public meeting taking place snaith primary sch...</td>\n",
       "      <td>0.593255</td>\n",
       "      <td>0.390547</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kev Taylor</td>\n",
       "      <td>250,000 litres of flood waters pumped away eve...</td>\n",
       "      <td>litre flood water pumped away every minute sti...</td>\n",
       "      <td>0.792955</td>\n",
       "      <td>0.188807</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Phil Shillito</td>\n",
       "      <td>The rain might have stopped but the multi agen...</td>\n",
       "      <td>rain might stopped multi agency response affec...</td>\n",
       "      <td>0.737688</td>\n",
       "      <td>0.253263</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Adam Tunningley</td>\n",
       "      <td>Media duties in #Snaith for me this morning. A...</td>\n",
       "      <td>medium duty morning awful see home flooded des...</td>\n",
       "      <td>0.742428</td>\n",
       "      <td>0.229025</td>\n",
       "      <td>0.028548</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CDW</td>\n",
       "      <td>@HumbersideFire And the winners of the worst j...</td>\n",
       "      <td>winner worst joke year</td>\n",
       "      <td>0.918154</td>\n",
       "      <td>0.067271</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mollie brooks</td>\n",
       "      <td>@EllieSimmonds1 @HumbersideFire Apparently thi...</td>\n",
       "      <td>apparently fake grown adult pretending he post...</td>\n",
       "      <td>0.933319</td>\n",
       "      <td>0.063430</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Andy Creasey</td>\n",
       "      <td>Again people refuse the listen or act on warni...</td>\n",
       "      <td>people refuse listen act warning obvious sign ...</td>\n",
       "      <td>0.629452</td>\n",
       "      <td>0.352369</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Peter Anderson</td>\n",
       "      <td>@krispygreen84 @HumbersideFire @officialgtfc I...</td>\n",
       "      <td>lucky get</td>\n",
       "      <td>0.648431</td>\n",
       "      <td>0.286872</td>\n",
       "      <td>0.064697</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Nickynoo/Aquanaught/conservationist</td>\n",
       "      <td>Today after a trip around the reserve I found ...</td>\n",
       "      <td>today trip around reserve found call could wit...</td>\n",
       "      <td>0.536601</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.035647</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Kevin Childs</td>\n",
       "      <td>@NELCouncil @HumberbeatNEL @HumbersideFire Be ...</td>\n",
       "      <td>nice thing around ward east west marsh problem...</td>\n",
       "      <td>0.637865</td>\n",
       "      <td>0.300916</td>\n",
       "      <td>0.061219</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Nick</td>\n",
       "      <td>@CCLeeFreeman @Humberbeat @HumbersideFire @EMA...</td>\n",
       "      <td>emergency worker assaulted must full extent la...</td>\n",
       "      <td>0.636483</td>\n",
       "      <td>0.352187</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>East Midlands Ambulance Service NHS Trust</td>\n",
       "      <td>Our General Manager for Lincolnshire, Sue Cous...</td>\n",
       "      <td>general manager lincolnshire sue cousland morn...</td>\n",
       "      <td>0.912067</td>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Gareth smith</td>\n",
       "      <td>@BrocklesbyLtd @HumbersideFire Devastating new...</td>\n",
       "      <td>devastating news sorry rob everyone involved b...</td>\n",
       "      <td>0.497504</td>\n",
       "      <td>0.348119</td>\n",
       "      <td>0.154377</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Greatest Hits Radio York &amp; North Yorkshire</td>\n",
       "      <td>NEWS - Huge vegetable oil fire in East Yorkshi...</td>\n",
       "      <td>news huge vegetable oil fire east yorkshire pic</td>\n",
       "      <td>0.544575</td>\n",
       "      <td>0.433751</td>\n",
       "      <td>0.021675</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Phillip Norton</td>\n",
       "      <td>The A180 is closed eastbound from Barnetby Top...</td>\n",
       "      <td>closed eastbound barnetby top brocklesby inter...</td>\n",
       "      <td>0.503025</td>\n",
       "      <td>0.480293</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UK Fire Rescue Photos</td>\n",
       "      <td>@Ball01B @HumbersideFire They looked terrible ...</td>\n",
       "      <td>looked terrible aswell fair think snaith one m...</td>\n",
       "      <td>0.856355</td>\n",
       "      <td>0.134946</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Stew B</td>\n",
       "      <td>@fireenguk @HumbersideFire Those Volvos were t...</td>\n",
       "      <td>volvos terrible two lgv training slow get mph ...</td>\n",
       "      <td>0.617543</td>\n",
       "      <td>0.356642</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Adam Craig, PB (Xe/Xer/Xerxes)</td>\n",
       "      <td>@UniofHull @HullPoliticsDep employee, Justin M...</td>\n",
       "      <td>employee justin morris stalker harasser instig...</td>\n",
       "      <td>0.963156</td>\n",
       "      <td>0.034609</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>St Richard's Academy</td>\n",
       "      <td>Making children more aware about domestic abus...</td>\n",
       "      <td>making child aware domestic abuse</td>\n",
       "      <td>0.528476</td>\n",
       "      <td>0.457157</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Wolds View Garage</td>\n",
       "      <td>@HumbersideFire North Cave beck had burst it's...</td>\n",
       "      <td>north cave beck burst bank footpath bridge pap...</td>\n",
       "      <td>0.592032</td>\n",
       "      <td>0.395054</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Susan Chandler 💙🇺🇦</td>\n",
       "      <td>@CoultishNick @21_hardy @HumberbeatRoads @Radi...</td>\n",
       "      <td>heartbreaking</td>\n",
       "      <td>0.818087</td>\n",
       "      <td>0.161149</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>caroline bilton</td>\n",
       "      <td>Main slip road off A1079 into Beverley closed ...</td>\n",
       "      <td>main slip road beverley closed due flooding ho...</td>\n",
       "      <td>0.658541</td>\n",
       "      <td>0.328864</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Hull Flood Risk</td>\n",
       "      <td>Hopefully today's rain will not cause us more ...</td>\n",
       "      <td>hopefully today rain cause u problem remember ...</td>\n",
       "      <td>0.540422</td>\n",
       "      <td>0.419639</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Miriam Heppell 💙MSc FCIPD</td>\n",
       "      <td>Startling statistics from Simon Gallow, Develo...</td>\n",
       "      <td>startling statistic simon gallow development d...</td>\n",
       "      <td>0.772055</td>\n",
       "      <td>0.218688</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           User  \\\n",
       "0                                           Bev   \n",
       "1                                       Nigel 💙   \n",
       "2                                       Nigel 💙   \n",
       "3                            Iain Joseph Gorry*   \n",
       "4               North East Lincolnshire Council   \n",
       "5                          South Yorkshire Fire   \n",
       "6   Humberside Police - North East Lincolnshire   \n",
       "7                            Safer Roads Humber   \n",
       "8                           North Lincs Council   \n",
       "9                                     DC_LK1989   \n",
       "10                        Alan Clark 💙 🇺🇦 🇪🇺 🇬🇧   \n",
       "11                  Park Street Performing Arts   \n",
       "12                 Lincolnshire Fire and Rescue   \n",
       "13                                      russell   \n",
       "14                                    Mark Webb   \n",
       "15                             James Mitchinson   \n",
       "16                                  Bog-trotter   \n",
       "17                                          CSB   \n",
       "18                                   Rob Buckle   \n",
       "19                      Sheffield Environmental   \n",
       "20                                  Bog-trotter   \n",
       "21                                 chris spavin   \n",
       "22                                 Guy Hitchins   \n",
       "23                                Hull 4 Heroes   \n",
       "24                               Farmers Weekly   \n",
       "25                          PCSO Darren Bainton   \n",
       "26                                  Dave Nassau   \n",
       "27                                     Debs B 🌱   \n",
       "28     Elephant in The Room Disability Services   \n",
       "29                              RSPCA Frontline   \n",
       "30                                Howard Davies   \n",
       "31                                        Jon T   \n",
       "32                           Jazzmariner ⚫️⚪️😁👏   \n",
       "33                                Lankyshirelad   \n",
       "34                               Phillip Norton   \n",
       "35                                   Kev Taylor   \n",
       "36                                Phil Shillito   \n",
       "37                              Adam Tunningley   \n",
       "38                                          CDW   \n",
       "39                                mollie brooks   \n",
       "40                                 Andy Creasey   \n",
       "41                               Peter Anderson   \n",
       "42          Nickynoo/Aquanaught/conservationist   \n",
       "43                                 Kevin Childs   \n",
       "44                                         Nick   \n",
       "45    East Midlands Ambulance Service NHS Trust   \n",
       "46                                 Gareth smith   \n",
       "47   Greatest Hits Radio York & North Yorkshire   \n",
       "48                               Phillip Norton   \n",
       "49                        UK Fire Rescue Photos   \n",
       "50                                       Stew B   \n",
       "51               Adam Craig, PB (Xe/Xer/Xerxes)   \n",
       "52                         St Richard's Academy   \n",
       "53                            Wolds View Garage   \n",
       "54                           Susan Chandler 💙🇺🇦   \n",
       "55                              caroline bilton   \n",
       "56                              Hull Flood Risk   \n",
       "57                    Miriam Heppell 💙MSc FCIPD   \n",
       "\n",
       "                                                Tweet  \\\n",
       "0   @GyAncient @nige_gallop @CCLeeFreeman @Cleeccs...   \n",
       "1   @GyAncient @BevskiMids @CCLeeFreeman @Cleeccsc...   \n",
       "2   @BevskiMids @CCLeeFreeman @Cleeccsc @Humberbea...   \n",
       "3   @Cleeccsc @JoRobbo68 @Humberbeat @HumbersideFi...   \n",
       "4   What are the biggest crime issues in North Eas...   \n",
       "5   We spent weeks tackling a fire on Hatfield Moo...   \n",
       "6   #Grimsby #Willows Attended an incident tonight...   \n",
       "7   A fire safety message today. With more people ...   \n",
       "8   Just because it's warm outside, it doesn't mea...   \n",
       "9   Unfortunately I’m going to say no...our street...   \n",
       "10  @Fionamills1 @Humber_01 @HareWolfy @LouiseWrit...   \n",
       "11  @HareWolfy @Humber_01 @Fionamills1 @LouiseWrit...   \n",
       "12  13:26 1/2 Wholetime and On-Call Crew from @Gai...   \n",
       "13  @HumbersideFire Glad no one injured 👍 i have b...   \n",
       "14  @CFOBlacksell @HumbersideFire @Humberbeat This...   \n",
       "15  @CFOBlacksell @HumbersideFire @Humberbeat Well...   \n",
       "16  @Marktur03393381 @SYFR @WYFRS @LancashireFRS @...   \n",
       "17  @PCSODarrenB @HumbersideFire Over the limit? N...   \n",
       "18  @sunkfarmer @PCSODarrenB @HumbersideFire Misse...   \n",
       "19  @BryonyHolroyd @AndyMbirder @4peatssake2 @Wint...   \n",
       "20  @paulbrear @HumbersideFire @SYFR Today (30 May...   \n",
       "21  @HumbersideFire Hi sorry to both you. Just won...   \n",
       "22  @HumbersideFire @SYFR Sooo much of this going ...   \n",
       "23  Five families had their lives turned upside do...   \n",
       "24  Top marks @HumbersideFire 👍 Sky lanterns start...   \n",
       "25  Please avoid using #SkyLanterns when showing y...   \n",
       "26  @Dr_Dan_1 @HumbersideFire @ChrisGPackham @Bell...   \n",
       "27  @BBCLookNorth @HumbersideFire Emergency servic...   \n",
       "28  @CEXHCC @21_hardy @Hullccnews @NHSHullCCG @NHS...   \n",
       "29  Thank you to @HumbersideFire for assisting Ins...   \n",
       "30  @shooter724 @Humberbeat @HumbersideFire The no...   \n",
       "31  The CPAD at #Patrington fire station is now ba...   \n",
       "32  @JKH62 @EnvAgencyYNE @johncurtinEA @EnvAgency ...   \n",
       "33  @EnvAgencyYNE @johncurtinEA @EnvAgency @TobyWi...   \n",
       "34  A public meeting is taking place at Snaith Pri...   \n",
       "35  250,000 litres of flood waters pumped away eve...   \n",
       "36  The rain might have stopped but the multi agen...   \n",
       "37  Media duties in #Snaith for me this morning. A...   \n",
       "38  @HumbersideFire And the winners of the worst j...   \n",
       "39  @EllieSimmonds1 @HumbersideFire Apparently thi...   \n",
       "40  Again people refuse the listen or act on warni...   \n",
       "41  @krispygreen84 @HumbersideFire @officialgtfc I...   \n",
       "42  Today after a trip around the reserve I found ...   \n",
       "43  @NELCouncil @HumberbeatNEL @HumbersideFire Be ...   \n",
       "44  @CCLeeFreeman @Humberbeat @HumbersideFire @EMA...   \n",
       "45  Our General Manager for Lincolnshire, Sue Cous...   \n",
       "46  @BrocklesbyLtd @HumbersideFire Devastating new...   \n",
       "47  NEWS - Huge vegetable oil fire in East Yorkshi...   \n",
       "48  The A180 is closed eastbound from Barnetby Top...   \n",
       "49  @Ball01B @HumbersideFire They looked terrible ...   \n",
       "50  @fireenguk @HumbersideFire Those Volvos were t...   \n",
       "51  @UniofHull @HullPoliticsDep employee, Justin M...   \n",
       "52  Making children more aware about domestic abus...   \n",
       "53  @HumbersideFire North Cave beck had burst it's...   \n",
       "54  @CoultishNick @21_hardy @HumberbeatRoads @Radi...   \n",
       "55  Main slip road off A1079 into Beverley closed ...   \n",
       "56  Hopefully today's rain will not cause us more ...   \n",
       "57  Startling statistics from Simon Gallow, Develo...   \n",
       "\n",
       "                                        Cleaned_Tweet  Negative   Neutral  \\\n",
       "0   bagger amazed knew walking football result yes...  0.519025  0.442044   \n",
       "1                                 blimey mick old dog  0.677478  0.285934   \n",
       "2   wondered rd right obvs due play rare midweek g...  0.763980  0.222234   \n",
       "3                          guy tweet date wrong think  0.664363  0.322601   \n",
       "4   biggest crime issue north east lincolnshire te...  0.662119  0.320535   \n",
       "5   spent week tackling fire hatfield moor despera...  0.560314  0.336407   \n",
       "6   attended incident tonight binbrook way group y...  0.889538  0.104743   \n",
       "7   fire safety message today people easy overload...  0.514286  0.462393   \n",
       "8   warm outside doesnt mean warm underwater cold ...  0.698401  0.289254   \n",
       "9   unfortunately im going say noour street would ...  0.875694  0.117654   \n",
       "10         didnt think would put outfit last incident  0.504043  0.470565   \n",
       "11     sliding batpole must fraught pain danger wolfy  0.644666  0.341539   \n",
       "12  wholetime oncall crew appliance misterton amp ...  0.538386  0.443323   \n",
       "13  glad one injured back work week realise mad li...  0.590768  0.373226   \n",
       "14  lazy gutterpress journalism embarrassment wors...  0.962897  0.034687   \n",
       "15  well said chris sorry medium making job difficult  0.747294  0.234820   \n",
       "16  day sequestration capacity lost c acre sssi na...  0.723867  0.256126   \n",
       "17                           limit sympathy im afraid  0.808927  0.180259   \n",
       "18                          missed wall end inch look  0.510658  0.459784   \n",
       "19  grazers would eaten low braches still place li...  0.612657  0.372969   \n",
       "20  today may day amp day use helicopter show seri...  0.852878  0.140245   \n",
       "21  hi sorry wondered letter posted mum letter box...  0.871667  0.120409   \n",
       "22  sooo much going present avoidable sadly helico...  0.521803  0.400316   \n",
       "23  five family life turned upside arsonist hull i...  0.766391  0.223161   \n",
       "24  top mark sky lantern start fire deadly farm an...  0.744505  0.243972   \n",
       "25  please avoid using showing appreciation nh amp...  0.772356  0.217180   \n",
       "26  please please please please dont set sky lante...  0.963210  0.034221   \n",
       "27  emergency service enough dealing earth lantern...  0.686192  0.303560   \n",
       "28  also dedicated email cant use phone deaf non v...  0.709626  0.275995   \n",
       "29  thank assisting insp hutton evening bridlingto...  0.771515  0.213819   \n",
       "30                             nose know fooling etta  0.486248  0.454826   \n",
       "31  cpad fire station back running ive replaced un...  0.531859  0.422922   \n",
       "32  presumably dont agree science dredging would m...  0.492322  0.480894   \n",
       "33                 dredging sediment crap river start  0.892963  0.099527   \n",
       "34  public meeting taking place snaith primary sch...  0.593255  0.390547   \n",
       "35  litre flood water pumped away every minute sti...  0.792955  0.188807   \n",
       "36  rain might stopped multi agency response affec...  0.737688  0.253263   \n",
       "37  medium duty morning awful see home flooded des...  0.742428  0.229025   \n",
       "38                             winner worst joke year  0.918154  0.067271   \n",
       "39  apparently fake grown adult pretending he post...  0.933319  0.063430   \n",
       "40  people refuse listen act warning obvious sign ...  0.629452  0.352369   \n",
       "41                                          lucky get  0.648431  0.286872   \n",
       "42  today trip around reserve found call could wit...  0.536601  0.427751   \n",
       "43  nice thing around ward east west marsh problem...  0.637865  0.300916   \n",
       "44  emergency worker assaulted must full extent la...  0.636483  0.352187   \n",
       "45  general manager lincolnshire sue cousland morn...  0.912067  0.084404   \n",
       "46  devastating news sorry rob everyone involved b...  0.497504  0.348119   \n",
       "47    news huge vegetable oil fire east yorkshire pic  0.544575  0.433751   \n",
       "48  closed eastbound barnetby top brocklesby inter...  0.503025  0.480293   \n",
       "49  looked terrible aswell fair think snaith one m...  0.856355  0.134946   \n",
       "50  volvos terrible two lgv training slow get mph ...  0.617543  0.356642   \n",
       "51  employee justin morris stalker harasser instig...  0.963156  0.034609   \n",
       "52                  making child aware domestic abuse  0.528476  0.457157   \n",
       "53  north cave beck burst bank footpath bridge pap...  0.592032  0.395054   \n",
       "54                                      heartbreaking  0.818087  0.161149   \n",
       "55  main slip road beverley closed due flooding ho...  0.658541  0.328864   \n",
       "56  hopefully today rain cause u problem remember ...  0.540422  0.419639   \n",
       "57  startling statistic simon gallow development d...  0.772055  0.218688   \n",
       "\n",
       "    Positive Sentiment  Label  XLNET_Prediction  \n",
       "0   0.038931  negative      0                 0  \n",
       "1   0.036588  negative      0                 0  \n",
       "2   0.013785  negative      0                 0  \n",
       "3   0.013036  negative      0                 0  \n",
       "4   0.017346  negative      0                 0  \n",
       "5   0.103279  negative      1                 1  \n",
       "6   0.005718  negative      1                 0  \n",
       "7   0.023321  negative      0                 0  \n",
       "8   0.012345  negative      0                 0  \n",
       "9   0.006652  negative      0                 0  \n",
       "10  0.025392  negative      0                 0  \n",
       "11  0.013795  negative      0                 1  \n",
       "12  0.018291  negative      1                 0  \n",
       "13  0.036006  negative      1                 0  \n",
       "14  0.002416  negative      0                 0  \n",
       "15  0.017886  negative      0                 0  \n",
       "16  0.020007  negative      0                 0  \n",
       "17  0.010814  negative      0                 0  \n",
       "18  0.029558  negative      0                 0  \n",
       "19  0.014374  negative      1                 1  \n",
       "20  0.006877  negative      0                 0  \n",
       "21  0.007924  negative      0                 0  \n",
       "22  0.077880  negative      0                 1  \n",
       "23  0.010447  negative      0                 0  \n",
       "24  0.011523  negative      0                 1  \n",
       "25  0.010464  negative      1                 0  \n",
       "26  0.002569  negative      1                 0  \n",
       "27  0.010248  negative      0                 0  \n",
       "28  0.014379  negative      0                 0  \n",
       "29  0.014666  negative      0                 0  \n",
       "30  0.058925  negative      0                 0  \n",
       "31  0.045219  negative      0                 0  \n",
       "32  0.026784  negative      0                 0  \n",
       "33  0.007510  negative      0                 0  \n",
       "34  0.016198  negative      0                 0  \n",
       "35  0.018238  negative      0                 1  \n",
       "36  0.009050  negative      0                 0  \n",
       "37  0.028548  negative      1                 0  \n",
       "38  0.014574  negative      0                 0  \n",
       "39  0.003251  negative      0                 0  \n",
       "40  0.018179  negative      0                 0  \n",
       "41  0.064697  negative      0                 0  \n",
       "42  0.035647  negative      0                 0  \n",
       "43  0.061219  negative      0                 0  \n",
       "44  0.011330  negative      0                 0  \n",
       "45  0.003528  negative      0                 0  \n",
       "46  0.154377  negative      0                 0  \n",
       "47  0.021675  negative      1                 0  \n",
       "48  0.016683  negative      1                 1  \n",
       "49  0.008699  negative      0                 0  \n",
       "50  0.025815  negative      0                 0  \n",
       "51  0.002236  negative      0                 0  \n",
       "52  0.014367  negative      0                 0  \n",
       "53  0.012914  negative      1                 1  \n",
       "54  0.020764  negative      0                 0  \n",
       "55  0.012595  negative      1                 1  \n",
       "56  0.039939  negative      0                 0  \n",
       "57  0.009258  negative      0                 0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d39a79-cd49-4b04-bcc6-b6d82273de99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
